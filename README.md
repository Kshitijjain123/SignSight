# SignSight: AI Wearable Translator for Deaf-Blind Communication

ðŸŽ¯ Goal: Translate tactile sign language into text/speech using AI and sensor simulation.

## Features
- Simulated sensor data (flex, pressure, motion)
- LSTM model for gesture classification
- Reverse translation: text â†’ vibration pattern
- Future-ready for TinyML deployment

## Tech Stack
- Python, TensorFlow/Keras
- Google Colab, GitHub
- Optional: Arduino, ESP32, TinyML

## Demo
Coming soon: Web-based interface + video walkthrough

## Author
Kshitij â€” CSE Student, passionate about ethical AI & assistive tech
